"""
Generate model and training configs for hyperparameter tuning.

`generate_model_config` generates a complete model config with all required
hyperparameters based on a `basic_config` dict, which is loaded from a
pre-defined json file. The main architecture, including number of layers and
layer types should be defined in that pre-defined json file. The
hyperparameters that the user does not want to tune should also be specified
in the json file. The hyperparameters that are missing in the json file will
be generated by `generate_model_config` to complete the model config.

`generate_train_config`.
"""
from __future__ import absolute_import, division, print_function

import argparse
import json
import os
from collections import OrderedDict
from copy import deepcopy

import numpy as np
from range_specs import (LAYER_CATEGORY_TYPE_SPECS, LAYER_RANGE_SPECS,
                         TRAIN_CATEGORY_TYPE_SPECS, TRAIN_RANGE_SPECS)
from utils import SEP


def sample_value(low, high, scale="linear", is_int=False, random_state=None):
    """Samples a numeric variable."""
    if random_state:
        v = random_state.uniform(low, high)
    else:
        v = np.random.uniform(low, high)

    if scale == "log2":
        v = 2**v
    elif scale == "log":
        v = np.exp(v)
    elif scale == "log10":
        v = 10**v
    elif scale == "linear":
        pass
    else:
        raise ValueError('Scale %s not supported.' % scale)

    return int(v) if is_int else v


def sample_category(categories, random_state=None):
    """Samples a categorical variable."""
    if random_state:
        c = random_state.choice(categories).tolist()
    else:
        c = np.random.choice(categories).tolist()
    return c


def sample_variable(var_name, fixed_hps, is_category_type=False,
                    **sample_spec):
    """Checks if a HP variable is pre-defined and fixed and samples if not."""
    if var_name in fixed_hps:
        return fixed_hps[var_name]
    if is_category_type:
        return sample_category(**sample_spec)
    else:
        return sample_value(**sample_spec)


def sample_layer_hps(layer_type, random_state=None, **fixed_hps):
    """Samples hps of a layer based on the given layer type."""
    if layer_type not in LAYER_RANGE_SPECS:
        raise NotImplementedError(
            "Layer type %s is not in the supported list: %s." %
            (layer_type, ", ".join(LAYER_RANGE_SPECS.keys())))

    is_category_types = LAYER_CATEGORY_TYPE_SPECS[layer_type]
    sample_specs = LAYER_RANGE_SPECS[layer_type]
    for var_name in sample_specs:
        sample_specs[var_name]["random_state"] = random_state

    layer_hps = OrderedDict()
    for var_name in sorted(sample_specs):
        layer_hps[var_name] = sample_variable(
            var_name,
            fixed_hps,
            is_category_type=is_category_types.get(var_name, False),
            **sample_specs[var_name])

    return layer_hps


def generate_model_config(basic_model_config, random_state=None):
    """Generates a complete model config based on the `basic_model_config`."""
    config = OrderedDict()
    for part in basic_model_config:
        config[part] = OrderedDict()
        for layer_name in basic_model_config[part]:
            basic_layer_hps = deepcopy(basic_model_config[part][layer_name])
            layer_type = basic_layer_hps.pop("layer_type")
            layer_hps = sample_layer_hps(
                layer_type, random_state=random_state, **basic_layer_hps)
            layer_config = OrderedDict()
            layer_config["layer_type"] = layer_type
            layer_config.update(layer_hps)
            config[part][layer_name] = layer_config
    return config


def generate_train_config(basic_train_config, random_state=None):
    config = {}
    for hp_name in sorted(TRAIN_RANGE_SPECS):
        sample_spec = TRAIN_RANGE_SPECS[hp_name]
        sample_spec["random_state"] = random_state
        config[hp_name] = sample_variable(
            hp_name,
            basic_train_config,
            is_category_type=TRAIN_CATEGORY_TYPE_SPECS.get(hp_name, False),
            **sample_spec)
    return config


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description='Model configuration generator.')
    parser.add_argument("--config_path", default="./data/hp_configs")
    parser.add_argument(
        "--basic_model_config_file",
        default="./configs/support__surv_diff_eq.json")
    parser.add_argument(
        "--basic_train_config_file", default="./configs/train.json")
    parser.add_argument("--random_seed", type=int, default=0)
    parser.add_argument("--starting_trial", type=int, default=0)
    parser.add_argument("--num_trials", type=int, default=50)
    args = parser.parse_args()

    exp_config_path = args.config_path
    if not os.path.exists(exp_config_path):
        os.makedirs(exp_config_path)

    # Load basic configs.
    with open(args.basic_model_config_file) as f:
        basic_model_config = json.load(f, object_pairs_hook=OrderedDict)
    with open(args.basic_train_config_file) as f:
        basic_train_config = json.load(f, object_pairs_hook=OrderedDict)
    # Replace default range specs with custom specs.
    if "custom_layer_range_specs" in basic_model_config:
        custom_layer_range_specs = basic_model_config.pop(
            "custom_layer_range_specs")
        for layer_type in custom_layer_range_specs:
            specs = custom_layer_range_specs[layer_type]
            for var_name in specs:
                LAYER_RANGE_SPECS[layer_type][var_name] = specs[var_name]
    if "custom_train_range_specs" in basic_model_config:
        custom_train_range_specs = basic_model_config.pop(
            "custom_train_range_specs")
        for hp_name in custom_train_range_specs:
            TRAIN_RANGE_SPECS[hp_name] = custom_train_range_specs[hp_name]
    # Random seed.
    random_state = np.random.RandomState(args.random_seed)
    # Use model config file name as the base file name.
    base_filename = os.path.basename(args.basic_model_config_file)
    base_filename = os.path.splitext(base_filename)[0]
    for i in range(args.starting_trial, args.starting_trial + args.num_trials):
        # Complete the model config based on basic_model_config.
        model_config = generate_model_config(basic_model_config, random_state)
        # Dump config to a json file
        filename = SEP.join([base_filename, "%d" % i, "model.json"])
        with open(os.path.join(exp_config_path, filename), "w") as f:
            json.dump(model_config, f, indent=4)

        # Generate train config.
        train_config = generate_train_config(basic_train_config, random_state)
        # Dump config to a json file
        filename = SEP.join([base_filename, "%d" % i, "train.json"])
        with open(os.path.join(exp_config_path, filename), "w") as f:
            json.dump(train_config, f, indent=4)
